import six
from _typeshed import Incomplete
from collections.abc import Generator

class KafkaProducer:
    def bootstrap_connected(self): ...
    
    DEFAULT_CONFIG: Incomplete
    _COMPRESSORS: Incomplete
    config: Incomplete
    _metrics: Incomplete
    _accumulator: Incomplete
    _metadata: Incomplete
    _sender: Incomplete
    _closed: bool
    _cleanup: Incomplete
    def __init__(self, **configs) -> None: ...
    def _cleanup_factory(self): ...
    def _unregister_cleanup(self) -> None: ...
    def __del__(self): ...
    def close(self, timeout: Incomplete | None = ...) -> None: ...
    def partitions_for(self, topic): ...
    def _max_usable_produce_magic(self): ...
    def _estimate_size_in_bytes(self, key, value, headers=...): ...
    def send(self, topic, value: Incomplete | None = ..., key: Incomplete | None = ..., headers: Incomplete | None = ..., partition: Incomplete | None = ..., timestamp_ms: Incomplete | None = ...): ...
    def flush(self, timeout: Incomplete | None = ...) -> None: ...
    def _ensure_valid_record_size(self, size) -> None: ...
    def _wait_on_metadata(self, topic, max_wait): ...
    def _serialize(self, f, topic, data): ...
    def _partition(self, topic, partition, key, value, serialized_key, serialized_value): ...
    def metrics(self, raw: bool = ...): ...


class KafkaConsumer(six.Iterator):
    DEFAULT_CONFIG: Incomplete
    DEFAULT_SESSION_TIMEOUT_MS_0_9: int
    config: Incomplete
    _metrics: Incomplete
    _client: Incomplete
    _subscription: Incomplete
    _fetcher: Incomplete
    _coordinator: Incomplete
    _closed: bool
    _iterator: Incomplete
    _consumer_timeout: Incomplete
    def __init__(self, *topics, **configs) -> None: ...
    def bootstrap_connected(self): ...
    def assign(self, partitions) -> None: ...
    def assignment(self): ...
    def close(self, autocommit: bool = ...) -> None: ...
    def commit_async(self, offsets: Incomplete | None = ..., callback: Incomplete | None = ...): ...
    def commit(self, offsets: Incomplete | None = ...) -> None: ...
    def committed(self, partition, metadata: bool = ...): ...
    def _fetch_all_topic_metadata(self) -> None: ...
    def topics(self): ...
    def partitions_for_topic(self, topic): ...
    def poll(self, timeout_ms: int = ..., max_records: Incomplete | None = ..., update_offsets: bool = ...): ...
    def _poll_once(self, timeout_ms, max_records, update_offsets: bool = ...): ...
    def position(self, partition): ...
    def highwater(self, partition): ...
    def pause(self, *partitions) -> None: ...
    def paused(self): ...
    def resume(self, *partitions) -> None: ...
    def seek(self, partition, offset) -> None: ...
    def seek_to_beginning(self, *partitions) -> None: ...
    def seek_to_end(self, *partitions) -> None: ...
    def subscribe(self, topics=..., pattern: Incomplete | None = ..., listener: Incomplete | None = ...) -> None: ...
    def subscription(self): ...
    def unsubscribe(self) -> None: ...
    def metrics(self, raw: bool = ...): ...
    def offsets_for_times(self, timestamps): ...
    def beginning_offsets(self, partitions): ...
    def end_offsets(self, partitions): ...
    def _use_consumer_group(self): ...
    def _update_fetch_positions(self, partitions) -> None: ...
    def _message_generator_v2(self) -> Generator[Incomplete, None, None]: ...
    def _message_generator(self) -> Generator[Incomplete, None, None]: ...
    def _next_timeout(self): ...
    def __iter__(self): ...
    def __next__(self): ...
    def next_v2(self): ...
    def next_v1(self): ...
    def _set_consumer_timeout(self) -> None: ...
